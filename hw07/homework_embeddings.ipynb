{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги в NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы научимся работать с моделями для построения векторных представлений текста. Загрузим и потестируем предобученные модели, посмотрим, какие свойства и функции у них есть, обучим свою модель и с помощью нее улучшим качество кластеризации(и/или классификации) текстов.\n",
    "\n",
    "Перед тем как приступать к выполнению задания не забудьте выполнить команду pip install -r <path_to_rep_requirements.txt> для того, чтобы в вашем виртуальном окружении были установлены правильные версии python пакетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:57:26.693546Z",
     "start_time": "2019-04-14T21:57:25.788955Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import warnings\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:58:52.231976Z",
     "start_time": "2019-04-14T14:58:51.950367Z"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "plt.style.use('default')\n",
    "figsize(12, 9)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "mpl.rcParams['font.family'] = 'Ubuntu'\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14)\n",
    " \n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем rucorpora 15 с [диска](https://yadi.sk/d/fLRMFhm03Pbs98).\n",
    "Либо выбираем предобученную модель с https://rusvectores.org/ru/models/. Выбор нужно обосновать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:59:15.998621Z",
     "start_time": "2019-04-14T14:59:15.995267Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_ruscorpora = 'ruscorpora.model.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим обученную на ruscorpora модель word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:03:16.478785Z",
     "start_time": "2019-04-14T15:02:59.209097Z"
    }
   },
   "outputs": [],
   "source": [
    "model_word2vec = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    path_to_ruscorpora,\n",
    "    binary=True\n",
    ")\n",
    "model_word2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим, как с ней обращаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть наиболее похожие на конкретное слово слова. Попробуйте свойства векторов word2vec: и подумайте какие слова нужно послать на вход, чтобы получить на выходе слова \"школа\",  \"машинное\", \"обучение\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:03:58.399470Z",
     "start_time": "2019-04-14T15:03:57.356321Z"
    }
   },
   "outputs": [],
   "source": [
    "model_word2vec.most_similar(positive=['корабль'],\n",
    "                            negative=['парус'],\n",
    "                            topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:03:59.361665Z",
     "start_time": "2019-04-14T15:03:59.319135Z"
    }
   },
   "outputs": [],
   "source": [
    "model_word2vec.most_similar(positive=['корабль', 'летать'],\n",
    "                            negative=['плавать'],\n",
    "                            topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:04:00.007662Z",
     "start_time": "2019-04-14T15:03:59.966543Z"
    }
   },
   "outputs": [],
   "source": [
    "model_word2vec.most_similar(positive=['шахтер'],\n",
    "                            negative=['грязь'],\n",
    "                            topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:04:00.404024Z",
     "start_time": "2019-04-14T15:04:00.358100Z"
    }
   },
   "outputs": [],
   "source": [
    "model_word2vec.most_similar(positive=['учение', 'тьма'],\n",
    "                            negative=['свет'],\n",
    "                            topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще есть функция, которая выводит лишнее слово в строке. Попробуйте придумать пример, с которым word2vec не справится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:04:19.569167Z",
     "start_time": "2019-04-14T15:04:19.561422Z"
    }
   },
   "outputs": [],
   "source": [
    "model_word2vec.doesnt_match(\"коньяк компот водка пиво\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая выводит сходство между словами.  С ее помощью можно понимать значение слова нефть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_word2vec.similarity('нефть', 'газ'))\n",
    "print(model_word2vec.similarity('нефть', 'вода'))\n",
    "print(model_word2vec.similarity('нефть', 'водка'))\n",
    "print(model_word2vec.similarity('нефть', 'духи'))\n",
    "print(model_word2vec.similarity('нефть', 'компот'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или смотреть, где в России больше нефти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_word2vec.similarity('нефть', 'чечня'))\n",
    "print(model_word2vec.similarity('нефть', 'якутск'))\n",
    "print(model_word2vec.similarity('нефть', 'москва'))\n",
    "print(model_word2vec.similarity('нефть', 'саратов'))\n",
    "print(model_word2vec.similarity('нефть', 'сибирь'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 0\n",
    "Допишите своих интересных примеров, характеризующих word2vec, попробуйте обосновать полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:05:19.270564Z",
     "start_time": "2019-04-14T15:05:19.267119Z"
    }
   },
   "outputs": [],
   "source": [
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь давайте обучим собственную модель\n",
    "В качестве обучающего корпуса возьмем новости по 20 темам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:05:28.604520Z",
     "start_time": "2019-04-14T15:05:27.941053Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all = fetch_20newsgroups(subset='train')\n",
    "print(train_all.target_names, \" - 20 возможных тем\")\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    subset='train', \n",
    "    categories=['comp.sys.mac.hardware', 'soc.religion.christian', 'rec.sport.hockey'])\n",
    "\n",
    "dataset.data[0].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 1\n",
    "\n",
    "Предобработаем эти новости. Выкинем цифры, знаки пунктуации, переведем в нижний регистр, разобьем на слова.\n",
    "\n",
    "Нормализуйте слова, например с помощью модуля nltk (или используйте любой другой способ на ваш выбор)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:08:42.646635Z",
     "start_time": "2019-04-14T15:08:42.642724Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(raw_text):\n",
    "    preprocessed_text = <Ваш код>\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:08:43.264213Z",
     "start_time": "2019-04-14T15:08:43.253424Z"
    }
   },
   "outputs": [],
   "source": [
    "data_normalized = [normalize(news) for news in tqdm(dataset.data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучающий корпус готов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:08:59.774601Z",
     "start_time": "2019-04-14T15:08:54.996030Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = data_normalized\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:11:25.147119Z",
     "start_time": "2019-04-14T15:11:06.040313Z"
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(iter=1)  # Инициализируем модель.\n",
    "model.build_vocab(sentences)  # Строим словарь.\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=20)  # Тренируем модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем слова из первой новости в новом векторном пространстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T15:11:39.600209Z",
     "start_time": "2019-04-14T15:11:39.591471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Берем слова из первой новости, достаем соостветствующие векторы,\n",
    "# выбрасываем слова, для которых векторов нет. \n",
    "# Подумайте - как так могло получится, что нет векторов?\n",
    "labels = []\n",
    "embeddings = []\n",
    "data_to_tsne = [item for sublist in data_normalized[:20] for item in sublist]\n",
    "\n",
    "for x in list(set(data_to_tsne)):\n",
    "    try:\n",
    "        embeddings.append(model[x])\n",
    "        labels.append(x)\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:10:59.003741Z",
     "start_time": "2019-04-14T21:10:58.997217Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 2\n",
    "Переведите многомерные векторы в двумерные (можно использовать TSNE, PCA, другие методы сокращения размерности), выберите часть слов для отрисовки. Как параметры и методы отрисовки влияют на полученный график? Как это можно обьяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_2d(embeddings):\n",
    "    return <Ваш код>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_to_draw = 1000\n",
    "low_dim_vectors = embeddings_2d(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рисуем только первые 1000 слов.\n",
    "labels_to_draw = [labels[i] for i in range(num_words_to_draw)]\n",
    "a = plot_with_labels(low_dim_vectors, labels_to_draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 3\n",
    "Проделайте аналогичную отрисовку и сжатие векторов для предобученной модели (для этого скачайте бинарник по этой [ссылке](https://code.google.com/archive/p/word2vec/) (файл GoogleNews-vectors-negative300) по аналогии с тем, как мы работали с русским корпусом. Сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Попробуем с помощью нашей модели улучшить качество кластеризации текстов\n",
    "Если вы не знаете, что такое кластеризация - почитать об этом можно по [ссылке](http://scikit-learn.org/stable/modules/clustering.html).\n",
    "\n",
    "Если вам все равно кажется, что это сложно, и вы чувствуете себя более уверено в задаче классификации - вместо задачи кластеризации можно рассматривать задачу классификации - тогда вместо функции quality используйте roc-auc из библиотеки scikit-learn, все остальные шаги предобработки и измерения признаков аналогичны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измерять качество кластеризации будем следующим образом - измерим количество правильных попаданий категории в кластеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(preds, target):\n",
    "    permutations = list(itertools.permutations([0, 1, 2]))\n",
    "    scores = []\n",
    "    for a, b, c in permutations:\n",
    "        mapping = {2 : a, 1: b, 0: c}\n",
    "        mapped_preds = [mapping[pred] for pred in preds]\n",
    "        scores.append(float(sum(mapped_preds != target)) / len(target))\n",
    "    return 1 - min(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 4\n",
    "Кластеризуйте датасет с заданием признаков с помощью one hot encoding - посмотрите на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 5\n",
    "Далее кластеризуем тексты на векторах, полученных из модели, которую мы сами обучили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая делает из предложения вектор - усредняет векторы всех слов в этом предложении. Если слова нет в словаре, то вместо вектора этого слова используется нулевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_feature_vector(words, model):\n",
    "    average_feature_vector = < Ваш код >\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию к нашим данным (уже нормализованным функцией normalize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized_vectors = [average_feature_vector(sent, model)\n",
    "                           for sent in data_normalized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сожмем массив признаков с помощью TSNE до нескольких компонент (попробуйте поварьировать число компонент)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dim_vectors = < Ваш код >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените алгоритм кластеризации (например, K-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:56:54.491658Z",
     "start_time": "2019-04-14T21:56:54.369537Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = MiniBatchKMeans(n_clusters=3).fit_predict(low_dim_vectors)\n",
    "quality(preds, dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Пункт 6\n",
    "\n",
    "Кластеризуйте тексты на векторах, полученных из предобученной модели. Какой результат получился лучше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Попробуйте получить аналогичные векторы и провести исследование на них с помощью fastq - [неплохое введение](https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 8\n",
    "С помощью библиотеки pytorch-pretrained-bert попробуйте получить векторы для ваших текстов ([инструкция](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/extract_features.py)) и провести исследование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Правила сдачи и критерии оценки:\n",
    "\n",
    "##### Как и куда сдавать:\n",
    "\n",
    "К блокноту нужно приложить краткий текстовый отчет в pdf, в котором вы описываете основные моменты: какие шаги выполняли, какое качество получали, а также какие графики рисовали и что это значит.\n",
    "\n",
    "Оба файла (ipynb блокнот с названием hw07_<имя>_<фамилия>.ipynb и pdf файл-отчет с названанием hw07_<имя>_<фамилия>_report.pdf) нужно загрузить через [гугл-форму](https://forms.gle/JbSQ6toQHQQc3CcF9).\n",
    "\n",
    "##### Обязательная часть (70% баллов)\n",
    "\n",
    "1) Пункт 1 - Пункт 7 (по 10% баллов за пункт).\n",
    "\n",
    "##### Продвинутая часть (30 % баллов)\n",
    "\n",
    "1) Пункт 8.\n",
    "\n",
    "2) Любые самые смелые идеи-эксперименты по тому, как можно улучшить качество моделей (пофильтровать какие-то части речи, редкие слова, использовать FastText).\n",
    "\n",
    "3) Интересные, необычные, просто хорошо сформулированные выводы о вашей работе в отчете.\n",
    "\n",
    "При проверке отчета будет обращаться внимание на анализ и оригинальность подходов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
